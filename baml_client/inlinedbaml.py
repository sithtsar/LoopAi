# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "agent.baml": "// 1. Define Verified Search Parameters\nclass SearchParams {\n  city string? @description(\"Normalized city name (e.g. 'Bengaluru' for 'Bangalore')\")\n  hospital_name string? @description(\"Partial name for fuzzy matching\")\n  limit int? @description(\"Number of results to return if specified\")\n}\n\n// 2. Define the Agent's Decision Structure\nclass AgentDecision {\n  thought string @description(\"Reasoning for the action\")\n  search SearchParams? @description(\"Populate ONLY if the user asks for hospital info\")\n  direct_reply string? @description(\"Populate if no database search is needed\")\n  clarifying_question string? @description(\"Populate if more info needed for search\")\n}\n\n// 3. The 'Brain' Function\nfunction DecideAction(query: string) -> AgentDecision {\n  client GroqLlama\n  prompt #\"\n    You are a hospital network assistant named Loop AI.\n    Input Context (History + Current Query):\n    \"{{ query }}\"\n\n    Analyze the input to determine the next action:\n    \n    1. **Search**: If the user is asking for hospital information (availability, location, list), extract 'city' and 'hospital_name'.\n       - Use conversation history to infer missing details (e.g., if previous turn was about 'Bangalore', 'What about Manipal?' implies Manipal in Bangalore).\n       - If 'city' is missing and cannot be inferred, DO NOT SEARCH. Instead, set 'clarifying_question' to ask for the city.\n    \n    2. **Clarify**: If the user's intent is hospital-related but vague (e.g., \"hospitals nearby\" without a location), set 'clarifying_question'.\n\n    3. **Out of Scope**: If the query is NOT about hospitals, health network, or greetings, set 'direct_reply' EXACTLY to:\n       \"I'm sorry, I can't help with that. I am forwarding this to a human agent.\"\n\n    4. **Direct Reply**: For greetings (e.g., \"Hello\", \"Who are you?\"), reply warmly as Loop AI.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// 4. The 'Synthesizer' Function\nfunction GenerateSpeech(query: string, data_context: string, clarifying: string) -> string {\n  client GroqLlama\n  prompt #\"\n    You are Loop AI, a hospital network assistant.\n    User Query: \"{{ query }}\"\n    Verified Database Data: \"{{ data_context }}\"\n    Clarifying Question: \"{{ clarifying }}\"\n\n    Answer the user warmly based *only* on the verified data above.\n    If clarifying is provided, ask that question.\n    Keep it conversational (under 2 sentences).\n    DO NOT use any emojis in your response.\n  \"#\n}",
    "clients.baml": "client<llm> GroqLlama {\n  provider openai\n  options {\n    base_url \"https://api.groq.com/openai/v1\"\n    api_key env.GROQ_API_KEY\n    model \"llama-3.3-70b-versatile\"\n  }\n}",
}

def get_baml_files():
    return _file_map